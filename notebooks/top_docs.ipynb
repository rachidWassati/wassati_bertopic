{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4280/4031566045.py:7: DtypeWarning: Columns (10,11,15,19,20,21,23,34,35,42,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_all_labelled.csv\", dtype={'year': str})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import pickle\n",
    "from bertopic import BERTopic\n",
    "\n",
    "df = pd.read_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_all_labelled.csv\", dtype={'year': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cattiaux/anaconda3/envs/wassati/lib/python3.9/site-packages/bertopic/vectorizers/_ctfidf.py:69: RuntimeWarning: divide by zero encountered in divide\n",
      "  idf = np.log((avg_nr_samples / df)+1)\n"
     ]
    }
   ],
   "source": [
    "### chargement du model bertopic\n",
    "\n",
    "def load_bertopic_model(filename):\n",
    "    \"\"\"\n",
    "    Load a BERTopic model and associated data from a file.\n",
    "    \n",
    "    :param filename: The name of the file to load the data from.\n",
    "    :return: A tuple containing the loaded BERTopic model, topics, probs, and docs variables.\n",
    "    \"\"\"\n",
    "    # Load the BERTopic model\n",
    "    topic_model = BERTopic.load(filename)\n",
    "    \n",
    "    # Load the topics, probs, and docs variables\n",
    "    with open(filename + '_data.pkl', 'rb') as f:\n",
    "        topics, probs, embeddings, docs = pickle.load(f)\n",
    "    \n",
    "    return topic_model, topics, probs, embeddings, docs\n",
    "\n",
    "topic_model, topics, probs, embeddings, docs = load_bertopic_model('../models/raw_keybert_bertopic_model')\n",
    "\n",
    "def create_merged_model(docs, bertopic_model, topics_to_merge_dict, label_names_dict):\n",
    "    \"\"\"\n",
    "    Create a new BERTopic model by merging topics from an existing model.\n",
    "\n",
    "    This function takes as input a list of documents `docs`, an existing BERTopic model `bertopic_model`, a dictionary `topics_to_merge_dict` specifying which topics to merge, and a dictionary `label_names_dict` specifying the labels for the merged topics.\n",
    "\n",
    "    The function creates a deep copy of the input BERTopic model and merges the specified topics using the `merge_topics` method. Then, it sets the topic labels for the merged model using the `set_topic_labels` method and the provided `label_names_dict`.\n",
    "\n",
    "    The resulting merged BERTopic model is then returned.\n",
    "\n",
    "    Parameters:\n",
    "        docs (list): A list of documents used to fit the BERTopic model.\n",
    "        bertopic_model (BERTopic): The input BERTopic model to be merged.\n",
    "        topics_to_merge_dict (dict): A dictionary specifying which topics to merge. The keys are the topic numbers to be merged, and the values are the topic numbers into which they should be merged.\n",
    "        label_names_dict (dict): A dictionary specifying the labels for the merged topics. The keys are the topic numbers, and the values are the corresponding labels.\n",
    "\n",
    "    Returns:\n",
    "        BERTopic: The resulting merged BERTopic model.\n",
    "    \"\"\"\n",
    "    topic_model_merged = copy.deepcopy(bertopic_model)\n",
    "    topic_model_merged.merge_topics(docs, topics_to_merge_dict)\n",
    "\n",
    "    # Create a dictionary to match the aggregated name to their corresponding topic number\n",
    "    mergedtopic_labels_dict = {i-1: item for i, item in enumerate(label_names_dict)}\n",
    "    # Set topic labels for the aggregated model\n",
    "    topic_model_merged.set_topic_labels(mergedtopic_labels_dict)\n",
    "\n",
    "    return topic_model_merged### Création du modèle bertopic aggrégé pour topics finaux\n",
    "\n",
    "# List of topics numbers. Each value of this list is a list that contains the topic number of the topics to join together\n",
    "topics_to_merge = [ [42,3,0,13], #Delivery Deadlines : challenges and strategies involved in managing delivery deadlines in logistics operations. (vert)\n",
    "                    [20,50,27], #Quotation and Pricing Strategies (vert bas)\n",
    "                    [35,32], #Touch Panels and Screens (rouge, haut)\n",
    "                    [40,36], #Frequency Converters : frequency converters used in industrial applications and the technical support provided by manufacturers and suppliers (rouge, suite)\n",
    "                    [37,21,6,12,9,4,1,14,16,31,19], #“Automation Components” : hardware and software components used in industrial automation systems. (rouge centre)\n",
    "                    [33,46,8], #Product Evaluation : evaluate the quality, affordability and reliability of products and services (rouge, fin)\n",
    "                    [44,51,23,41,49,57,22], #Customer Support : Reliability and Quality in Customer Service and Support (bleu ciel)\n",
    "                    [58,59], #Quick Customer Service (marron)\n",
    "                    [38,10,26,52,39,43], #Problem Solving and Communication (focus on the importance of being efficient and precise when solving problems) (jaune)\n",
    "                    [45,47,55,53,54], #Assistance and Guidance (noir)\n",
    "                    [29,30,11,24], #Power Supply Issues (2e vert, haut)\n",
    "                    [7,5,2,25,15,34,18,28,17], #Technical Support (2e vert, bas)\n",
    "                    [48,56] #None : positive feedback (2e rouge)\n",
    "]\n",
    "\n",
    "# Set the topic names for the new aggregated topic\n",
    "# It must match the order from the topics_to_merge list\n",
    "label_names = [\n",
    "    \"Outliers\",\n",
    "    \"Automation Components\",\n",
    "    \"Technical Support\",\n",
    "    \"Delivery Deadlines\",\n",
    "    \"Problem Solving & Comm\",\n",
    "    \"Power Supply Issues\",\n",
    "    \"Customer Support\", #Reliability and Quality in Customer Service and Support\n",
    "    \"Product Evaluation\",\n",
    "    \"Pricing\", #Quotation and Pricing Strategies\n",
    "    \"Assistance\", #Assistance and Guidance\n",
    "    \"Touch Screens\", #Touch Panels and Screens\n",
    "    \"Frequency Converters\",\n",
    "    \"Positive feedback\",\n",
    "    \"Quick Customer Service\"\n",
    "    ]\n",
    "\n",
    "# Create a new merged bertopic model \n",
    "topic_model_merged = create_merged_model(docs, topic_model, topics_to_merge, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_topic_docs(probabilities, df, topic, top_n_docs=len(df)):\n",
    "    \"\"\"\n",
    "    Get the top n documents for a specified topic.\n",
    "\n",
    "    Parameters:\n",
    "    probabilities (numpy.ndarray): The probabilities from the BERTopic model.\n",
    "    df (pandas.DataFrame): The dataframe containing the documents.\n",
    "    topic (int): The topic to get the top n documents for.\n",
    "    top_n_docs (int): The number of top documents to return. Defaults to the length of df.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing a dataframe with the top n documents for the specified topic and a list with their content.\n",
    "    \"\"\"\n",
    "    def sort_docs_with_same_prob(probabilities, prob, topic):\n",
    "        \"\"\"\n",
    "        Sort documents that have the same probability for a specified topic.\n",
    "\n",
    "        Parameters:\n",
    "        probabilities (numpy.ndarray): The probabilities from the BERTopic model.\n",
    "        prob (float): The probability to filter by.\n",
    "        topic (int): The topic to sort the documents for.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: An array containing the sorted indices of the documents that have the specified probability for the specified topic.\n",
    "        \"\"\"\n",
    "        # Get the indices of all documents that have the current probability for the defined topic\n",
    "        top_docs_indices = np.where(probabilities[:, topic] == prob)[0]\n",
    "        # Sort the probabilities for each document in descending order\n",
    "        sorted_probs = -np.sort(-probabilities[top_docs_indices], axis=1)\n",
    "        # Compute the score for each document based on the difference between their first and second scores\n",
    "        scores = sorted_probs[:, 0] - sorted_probs[:, 1]\n",
    "        # Sort these top documents based on their scores\n",
    "        sorted_top_docs_indices = top_docs_indices[np.argsort(scores)[::-1]]\n",
    "        \n",
    "        return sorted_top_docs_indices\n",
    "    \n",
    "    # Get the unique probabilities for the defined topic\n",
    "    unique_probs = np.unique(probabilities[:, topic])\n",
    "    # Sort the unique probabilities in descending order\n",
    "    sorted_unique_probs = np.sort(unique_probs)[::-1]\n",
    "    \n",
    "    # Initialize an empty list to store the sorted indices of all documents\n",
    "    sorted_docs_indices = []\n",
    "    \n",
    "    # Loop over the unique probabilities\n",
    "    for prob in sorted_unique_probs:\n",
    "        # Sort the documents that have the current probability for the defined topic\n",
    "        sorted_top_docs_indices = sort_docs_with_same_prob(probabilities, prob, topic)\n",
    "        # Append these indices to the list of sorted indices of all documents\n",
    "        sorted_docs_indices.extend(sorted_top_docs_indices)\n",
    "    \n",
    "    # Take the top n from this sorted list\n",
    "    final_top_docs_indices = np.array(sorted_docs_indices)[:top_n_docs]\n",
    "    \n",
    "    # Get the content of the top n documents from your dataframe\n",
    "    top_docs_df = df.iloc[final_top_docs_indices]\n",
    "    top_docs_content = top_docs_df[\"processed_data\"].to_list()\n",
    "    \n",
    "    return top_docs_df, top_docs_content\n",
    "\n",
    "def filter_docs(df, filter_column, filter_value):\n",
    "    \"\"\"\n",
    "    Filter a dataframe based on a specified column and value.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The dataframe to filter.\n",
    "    filter_column (str): The name of the column to filter by.\n",
    "    filter_value (str): The value to filter by in the specified column.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the filtered dataframe and a boolean mask indicating which rows match the specified filter.\n",
    "    \"\"\"\n",
    "    filter_mask = df[filter_column] == filter_value\n",
    "    return df[filter_mask], filter_mask\n",
    "\n",
    "# Filter the top docs based on the specified column and value\n",
    "filtered_top_docs, filter_mask = filter_docs(df, \"Account Country\", \"France\")\n",
    "top_docs_df, top_docs_content = get_top_topic_docs(topic_model_merged.probabilities_[filter_mask], filtered_top_docs, topic=2, top_n_docs=10)\n",
    "\n",
    "# top_docs_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wassati",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
